import OpenAI from "openai";
export type SessionDetails = {
    id: string;
    version: string;
};
export type LLMProvider = "openai" | "google" | "anthropic";
export type LLMModel = "gpt-3.5-turbo" | "gpt-4" | "gpt-4o" | "gpt-4o-mini" | "gpt-4o-2024-08-06" | "claude-3-5-sonnet-latest" | "claude-3-5-sonnet-20240620" | "gemini-1.5-flash-latest" | "gemini-1.5-pro-latest" | "o1-preview" | "o1" | "o1-mini" | "o3-mini-2025-01-31";
export interface ModelParameters {
    frequency_penalty?: number | null;
    logit_bias?: Record<string, number> | null;
    logprobs?: boolean | null;
    max_completion_tokens?: number | null;
    n?: number | null;
    presence_penalty?: number | null;
    response_format?: OpenAI.ChatCompletionCreateParamsNonStreaming["response_format"];
    seed?: number | null;
    stop?: string | null | Array<string>;
    stream_options?: OpenAI.ChatCompletionStreamOptions | null;
    temperature?: number | null;
    top_p?: number | null;
    user?: string;
    tool_choice?: OpenAI.Chat.Completions.ChatCompletionToolChoiceOption;
}
//# sourceMappingURL=index.d.ts.map