"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.query = void 0;
const zod_1 = require("openai/helpers/zod");
const zod_2 = require("zod");
const zod_to_json_schema_1 = __importDefault(require("zod-to-json-schema"));
const __1 = require("../..");
const trace_1 = require("../../trace");
const utils_1 = require("../utils");
async function query(base64Image, instruction, options = {
    responseFormat: zod_2.z.string(),
    model: "gpt-4o-mini",
}) {
    const mergedOptions = {
        responseFormat: zod_2.z.string(),
        model: "gpt-4o-mini",
        ...options,
    };
    const { responseFormat, model } = mergedOptions;
    const llm = new __1.LLM({
        provider: "openai",
    });
    const systemPrompt = `
You are given an image and an instruction. Use the "explanation" to
think it through, and then respond with the "answer".`;
    const isResponseString = responseFormat instanceof zod_2.z.ZodString;
    let extendedResponseFormat;
    if (isResponseString) {
        extendedResponseFormat = zod_2.z.object({
            explanation: zod_2.z.string(),
            answer: zod_2.z.string(),
        });
    }
    else {
        extendedResponseFormat = zod_2.z.object({
            explanation: zod_2.z.string(),
            answer: responseFormat,
        });
    }
    const session = (0, utils_1.getSessionDetails)();
    if (mergedOptions.telemetry?.tags && !trace_1.langfuseInstance) {
        console.warn("Telemetry keys are not set. Telemetry will not be sent.");
    }
    const trace = trace_1.langfuseInstance?.trace({
        name: "vision-query",
        sessionId: session.id,
        release: session.version,
        tags: ["vision", "vision-query", ...(mergedOptions?.telemetry?.tags || [])],
    });
    const temperature = 0.5;
    const generationTrace = trace?.generation({
        name: "query",
        model,
        modelParameters: {
            temperature,
        },
        input: {
            responseFormat: (0, zod_to_json_schema_1.default)(extendedResponseFormat, "responseFormat"),
            systemPrompt,
            userMessages: {
                instruction,
                image: base64Image,
            },
        },
    });
    trace?.update({
        input: {
            base64Image,
            instruction,
            options: {
                responseFormat: (0, zod_to_json_schema_1.default)(extendedResponseFormat, "responseFormat"),
                model,
            },
        },
    });
    const llmResponse = await llm.createChatCompletion({
        messages: [
            {
                role: "system",
                content: systemPrompt,
            },
            {
                role: "user",
                content: [
                    {
                        type: "image_url",
                        image_url: {
                            url: (0, utils_1.imageFormatForProvider)("openai", base64Image),
                        },
                    },
                    {
                        type: "text",
                        text: `Instruction: ${instruction}`,
                    },
                ],
            },
        ],
        model,
        modelParameters: {
            temperature: temperature,
        },
        responseFormat: (0, zod_1.zodResponseFormat)(extendedResponseFormat, "your_response"),
    });
    if (!llmResponse || !llmResponse.content) {
        throw new Error(`Query failed: no response content from LLM. Check the trace for more info: ${trace?.getTraceUrl()}`);
    }
    const response = llmResponse.content;
    const jsonData = JSON.parse(response);
    trace?.update({
        output: jsonData,
    });
    generationTrace?.end({
        output: jsonData,
        usage: {
            input: llm.promptTokens,
            output: llm.completionTokens,
            unit: "TOKENS",
        },
    });
    return responseFormat.parse(jsonData.answer);
}
exports.query = query;
